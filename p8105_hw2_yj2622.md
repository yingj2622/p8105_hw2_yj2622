Homework 2
================
Ying Jin
2020/9/24

This is the solution to homework 2\!

``` r
library(tidyverse)
```

    ## -- Attaching packages -------------------------------------- tidyverse 1.3.0 --

    ## √ ggplot2 3.3.2     √ purrr   0.3.4
    ## √ tibble  3.0.3     √ dplyr   1.0.2
    ## √ tidyr   1.1.2     √ stringr 1.4.0
    ## √ readr   1.3.1     √ forcats 0.5.0

    ## -- Conflicts ----------------------------------------- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Read and clean the Mr. Trash Wheel data:

``` r
mr_trash_wheel_data <- read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",sheet = "Mr. Trash Wheel",skip = 1,range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data:

``` r
precip_2018 <- read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",sheet = "2018 Precipitation",skip = 1) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 <- read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",sheet = "2017 Precipitation",skip = 1) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Combine annual precipitation:

``` r
month_df <- tibble(
  month = 1:12,
  month_name = month.name
)
precip_df <- bind_rows(precip_2017,precip_2018) %>% 
left_join( month_df, by = "month") %>% 
  select(-month) %>% 
  rename("month" ="month_name")
```

This dataset contains information from the Mr. Trash Wheel trash
collector in Baltimore, Maryland. The trash enters the innder harbor,
the trashwheel collectes that trash, and stores it in a dumpster.

  - The dataset contains information on year, month and trash collected,
    including some specific kind of trash. There are a total of 344 rows
    in the final dataset.

  - Additional data sheets include month precipitation data from 2014 to
    2019. The combined precipitation dataset has 24 rows and key
    variables are year, month and precipitation amount.

  - The total precipitation in 2018 was 70.33 inches.

\*The median number of sports balls in 2017 was 8.

## Problem 2

Read and clean NYC transit data:

``` r
nyc_transit_data <- read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE,"NO" = FALSE))
```

This dataset provides information about each entrance and exit for each
subway in NYC.

  - It contains information about station name, location, routes,vending
    or not, and whether it’s an entry.

  - There are total 1868 rows and 19 columns in this dataset.

  - My cleaning steps:
    
      - clean variable names;
    
      - select columns needed;
    
      - convert the values of `entry` to logical variables.

  - And these data are not tidy because how routes were organized are
    not proper.

Then I try to answer questions in problem 2:

First, I calculate the number of different subway stations:

``` r
n_diff_station <- distinct(nyc_transit_data,station_name,line) %>% 
  nrow
```

There are 465 different stations in the dataset.

Next, I try to find the number of stations with ADA compliance:

``` r
n_station_with_ada <- 
  select(nyc_transit_data,station_name,line,ada) %>% distinct(station_name,line,.keep_all = TRUE) %>% 
  filter(ada == TRUE) %>%
  nrow
```

There are 84 stations which are ADA compliant.

Then, I calculate the proportion of entrances/ exits without vending
allow entrance:

``` r
n_no_vending <- filter(nyc_transit_data,vending == "NO") %>% nrow

n_no_vending_entrance <- filter(nyc_transit_data,vending == "NO") %>% 
  filter(entry == TRUE) %>% 
  nrow

p_no_vending_entrance = n_no_vending_entrance/n_no_vending
```

There are 37.7% of entrances/exits without vending allow entrance.

To solve the rest of the problem, I reformat data to make route number
and route name become distinct variables. Since the value types of
columns start with “route” is different, I also convert those columns
whose values are double into character:

``` r
nyc_transit_tidy_data <- mutate(
  nyc_transit_data,
 across(route8:route11,as.character)) %>% 
  pivot_longer(
  cols = starts_with("route"),
  names_to = "route_name",
  names_prefix = "route",
  values_to = "route_number"
) %>% 
  drop_na(route_number)
```

Then get the table of distinct stations serving the A train, and ADA
compliance is included in this table:

``` r
station_serve_a_df <- select(nyc_transit_tidy_data,station_name,line,route_number,ada) %>% 
  distinct(station_name,line,.keep_all = TRUE) %>% 
  filter(route_number == "A")
```

So we can get that there are 60 stations serving A train

In the end, I get the number of stations serving A train which are ADA
compliant:

``` r
n_of_station_a_ada <- filter(station_serve_a_df,ada == TRUE) %>% nrow
```

So of the stations that serve the A train, there are 17 stations which
are ADA compliant.

## Problem 3

First, I read and clean the data in `pols-month.csv`:

``` r
pols_month_data <- read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>%
  separate(mon,c("year","month","day"),sep = "-") %>% 
  mutate(month = month.abb[as.numeric(month)]) %>% 
  mutate(president = ifelse(prez_gop != 0,"gop","dem")) %>% 
  select(-prez_gop,-prez_dem) %>% 
  select(-day)
```

Next, I read and clean the data in snp.csv in a similar way :

``` r
snp_data <- read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  separate(date,c("month","day","year"),sep = "/") %>% 
  relocate(year,month) %>% 
  mutate(month = as.numeric(month)) %>% 
  arrange(year,month) %>% 
  mutate(month = month.abb[month]) %>% 
  select(-day)
```

Then clean the unemployment dataset:

``` r
unemp_data <- read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment"
  ) %>% 
   janitor::clean_names() %>% 
  mutate(year = as.character(year))
```

After that, I merge these three datasets in order:

``` r
pol_snp_unemp_data <- left_join(pols_month_data,snp_data, by = c("year","month")) %>% 
  left_join(unemp_data,by = c("year","month"))
```

  - In the pols\_month dataset, there are 822 rows and 9 columns, and
    the range of year is from 1947 to 2015. It provides information
    about year, month, number of governors, senators and representatives
    who are democratic or republican respectively, and the president’s
    party at that time.

  - In the snp dataset, there are 787 rows and 3 columns. The year
    ranges from 1950 to2015. It provides information about year, month
    and the closing values of the S\&P stock index at that time.

  - In the unemployment dataset, there are 816 rows and 3 columns. The
    year ranges from 1948 to2015. This dataset contains information
    about year, month and percentage of unemployment in that time
    period.

  - Finally, the merged dataset have822 rows and11 columns. The year
    ranges from 1947 to2015. It includes all information in the three
    separate datasets.
